\section{Our Topic Models}\label{sec:plate_notation}
In this section, we detail the modifications that we have implemented to the existing models, outlined in \autoref{sec:preliminaries}.
We present three models, one for each of the metadata fields detailed in \autoref{sec:dataset}.
Two of the models: the Author and Category metadata models are based on the Author-topic \gls{lda} explained in \autoref{subsec:auth_prelim}.
Lastly the Taxonomy metadata model is based on \gls{pam}, which is explained in \autoref{subsec:pachinko_prelim}.

\subsection{Author-Topic \gls{lda} and Category-Topic \gls{lda}}
We model both of the metadata fields 'Author' and 'Category' similarly to the model by \citet{author_topic_2012} presented in \autoref{subsec:auth_prelim}.
The category model builds on the assumption that categories of the articles were chosen based on the content of the finished article and that local newspapers have their own unique topic preferences.
We find this model to be generally applicable to most metadata information, assuming that the metadata is either chosen based on the text of the documents (as with the category metadata) or that it has some impact on the text of the document (as with the author metadata).

For our category-topic model and our author-topic model, each document $d$ is associated with only one category $c_d$ from a set of categories $C$ and only one author $a_d$ from a set of authors $A$, rather than a vector.
This is due to our dataset never having more than one author or category for each document.
Unless otherwise stated, future mentions of the author-topic model are to our implementation of this model, rather than the model presented by \citet{author_topic_2012}.
The plate notation for our category and author \gls{lda} models can be seen in \autoref{fig:metadata_lda}.

\subsection{Pachinko Allocation}
In order to handle the hierarchical structure of the taxonomy metadata field, we use a hierarchical topic model, namely the \acrfull{pam} from \citet{li2006pachinko}.
Pachinko allocation generalizes \gls{lda}, making it possible to construct topic hierarchies based on any \gls{dag} structure.
\gls{pam} is a topic model focusing on finding topics of different abstraction levels and modeling the connections between these topics.

Each node in the \gls{dag} structure represents a topic in the pachinko allocation model. 
However, unlike \gls{lda} where topics are distributions over words, in \gls{pam} topics are multinomial distributions over words and/or other topics further down the hierarchy of the \gls{dag} structure.
An example of the \gls{dag} structure used in this paper is in \autoref{fig:pachinko_dag} where each level of the \gls{pam} is shown.
The idea behind the \gls{dag} structure is to be able to model correlations between topics and in turn make more coherent topics.
  
In this paper, we use a layered \gls{pam}, as in \cite{li2006pachinko}, meaning that the \gls{dag} structure is divided into layers where each layer is fully connected.
However, \citet{li2006pachinko} use four layers where we use five to capture more taxonomy fields.

We replicate some layers in our \gls{dag} structure based on the structure from the taxonomy field within our dataset, having some nodes represent a topic based on a specific taxonomy.
An example of this can be seen in \autoref{fig:pachinko_dag}, where we have the node "STEDER", and this is connected to "Danmark" in the third layer.
To make the algorithm construct the topics to be based on our taxonomies, we introduce a novel locking mechanism for the Gibbs sampler which we use to run \gls{pam}.
This mechanism is discussed further in \autoref{subsec:mod_pachinko}.

We use a five-level pachinko tree structure, following the format presented by \citet{li2006pachinko}.
The first layer is the root layer which all topics are a part of.
The last layer is the word layer consisting of one node for each word in the vocabulary of our corpus.
The second and third layers will be constructed based on the entries of the first two positions in our taxonomy metadata, meaning there will be one node for each unique sub-taxonomy entry that is in the first or second position in the taxonomy sequence (e.g. "STEDER" and "Danmark", which is taken from "STEDER/Danmark/Aalborg", but not "Aalborg" since it is in the third position).
We only use the first two layers for this, as these are among the most informative, and because introducing even more layers would slow down the training significantly, since the probability of all possible combinations of topics needs to be sampled for every word during training.
From our experiments, the training time for 50 epochs, increases from 12 hours to 130 hours between four and five level pachinko.
The fourth layer consists of $K = 90$ 'blank' topics, as with the other models we present in this paper.
This layer is added so that the model can construct its own topics based on the higher-level topics learned from our taxonomy metadata.

\input{figures/dag_structure}




\subsubsection{Modification to Pachinko Allocation}\label{subsec:mod_pachinko}
Normally when working with topic modeling, one does not know which topics will be present in the document set before training the model.
However, the taxonomy metadata fields provide some general subject names of different levels of abstraction and some amount of documents attached to these subject names.
This provides a unique opportunity for using the existing taxonomies as higher-level topics.
Without modification, \gls{pam} will find topics with the same structure as our taxonomy, but the taxonomy values would be disregarded during training since it would generate new taxonomy sequences.
However, in our case, we have a partially observed taxonomy and we want to use the existing meta-information to estimate the topics quicker and more accurately.
Although, only ${\sim}25\%$ of the documents in our dataset have an observed taxonomy.
To account for this, we lock taxonomy for the words in the observed documents to be in the corresponding topics within the \gls{pam} \gls{dag} instead of continuously sampling them using Gibbs sampling.
This creates a constant context for the taxonomy topics, which the documents with unobserved taxonomies will be fitted around.

Some of the documents have multiple taxonomies.
For these documents, one of the taxonomies is chosen randomly for each word in the document. 
