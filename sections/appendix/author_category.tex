\subsection{The author-category model}\label{sec:combination}
We have created a combination model, as an extension of our metadata models, to see whether using multiple metadata fields at the same time to draw topics, would affect the performance of the topic model.
The idea is that this model combination should give insight into what a model learns when multiple metadata influence the topics chosen.
The model we have created is the Author-Category combination model.
As the name suggests, this model includes an author-topic distribution and a category-topic distribution, and the plate notation can be seen in \autoref{fig:author_category_lda}.

To combine the Author and Category metadata, we multiply the topic distributions $\theta_a$ and $\theta_c$ and the topic word $\beta_w$ when sampling a new topic $t$ for word $w$.
\begin{equation}
	p_z = \frac{\theta_a}{C(\theta_a)} \cdot \frac{\theta_c}{C(\theta_c)} \cdot \frac{\beta_w}{C(\beta_w)}
\end{equation}
Where C() is a function that counts number of times the word or document is used within a topic.
Though, before sampling a new topic, we normalize it by the $L1$ norm, where we divide by sum of all variables, which also makes it a distribution. 
\begin{equation}
	dist = \frac{p_z}{\sum_{1}^{t} p_z}
\end{equation}
This makes both of the learned meta distributions influence the sampled word topics.

\begin{figure*}[ht]
	\centering
	\resizebox{.3\textwidth}{!}{%
		\input{figures/author_category_plate}
	}
	\caption{Plate notation for the Author-Category \gls{lda} model.}
	\label{fig:author_category_lda}
\end{figure*}

\input{sections/appendix/author_category_analysis.tex}

\input{tables/topic_examples.tex}