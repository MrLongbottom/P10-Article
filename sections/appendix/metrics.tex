\subsection{Topic coherence}\label{app:topic_coherence}
The equations, explanations, and values of the hyperparameters in this section are based on~\citet{Syed2017coherence} and the \textit{gensim} python package\footnote{\url{https://radimrehurek.com/gensim/}}.
Calculating topic coherence requires the following steps:

\begin{enumerate}
\item Topic-word segmentation into word set pairs
\item Word and word pair probability calculation
\item Word set confirmation measure
\item Aggregation of confirmation measures
\end{enumerate}

For segmentation, a set of word pairs $S$ is created, which pairs each word in the top-N most probable words $W$ in a specific topic $t$ with all other words in $W$.
$S$ is defined by \autoref{eq:set_of_word_pairs}.

\begin{equation}\label{eq:set_of_word_pairs}
	S = \{(W', W*)|W' = \{w_i\};w_i \in W;W* = W\}
\end{equation}

Before calculating word probabilities, a sliding window of size $s$ where $s =110$ is used to create a set of subdocuments $D_s$ over the document set $D$.
These subdocuments are used rather than the normal documents to capture some degree of word proximity.
Word probabilities are calculated based on how many documents, within the document set $D_s$, they occur in.
$p(w_i)$ is the number of subdocuments in which the word $w_i$ occurs divided by $|D_s|$.
$p(w_i, w_j)$ is the number of subdocuments in which both words occur divided by $|D_s|$. 

We create a \gls{npmi} matrix of size $|W|\times|W|$, with one entry per word pair combination in $W$.
\begin{equation}\label{eq:coherence_2}
	\text{NPMI}(w_i,w_j) =  \frac{\log\frac{p(w_i,w_j) + \epsilon}{p(w_i)\cdot p(w_j)}}{-log(p(w_i,w_j) + \epsilon)}
\end{equation}
\noindent where $\epsilon$ is a low number ($10^{-12}$) used to avoid $log(0)$.
The \gls{npmi} matrix describes how much each word occurs alone versus together with other words.
Each value is between $-1$ and $1$, with $-1$ meaning that the words never occur together and 1 meaning that they only occur together.

After having calculated the \gls{npmi} matrix, we construct context vectors for both elements $W'$ and $W*$ in each word-pair $S_i$, by summing over the rows of the \gls{npmi} matrix.
This summation describes how much each top word co-occurs with the other words in $W$.
\begin{equation}\label{eq:coherence_1}
	\overrightarrow{v}(W') = \left\{ \sum_{w_i \in W'} \text{NPMI}(w_i, w_j)^{\gamma} \right\}_{j=1,\dots,|W|}
\end{equation}
\noindent where $\gamma$ can be used to further prioritize higher values.
For this paper we use $\gamma = 1$, as recommended by \citet{Syed2017coherence}.

We now have a pair of context vectors for each word pair $S_i$ and we want to know how different these vectors are.
This is calculated using cosine similarity as a confirmation measure.
\begin{equation}\label{eq:coherence_3}
	\phi_{S_i}(\overrightarrow{u}, \overrightarrow{w}) = \frac
	{\sum_{i = 1}^{|W|} u_i \cdot w_i}
	{\|\overrightarrow{u}\|_2 \cdot \|\overrightarrow{w}\|_2}
\end{equation}

\noindent where $\overrightarrow{u}$ is the context vector $\overrightarrow{v}(W')$, and $\overrightarrow{w}$ is the context vector $\overrightarrow{v}(W^*)$.

Lastly, the confirmation measures are aggregated using the arithmetic mean, to achieve the coherence value of topic $t$.

\begin{equation}\label{eq:coherence_4}
	C_v = \frac{1}{|S|}\sum_{i=1}^{|S|}\phi_{S_i}
\end{equation}
