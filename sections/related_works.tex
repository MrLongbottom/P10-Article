\section{Related Work}\label{sec:related_work}

\citet{author_topic_2012} have developed an \gls{lda} model called the Author-Topic model, which incorporates authorship information in the \gls{lda} model.
Specifically, each document has a group of authors, where for each word an author is chosen uniformly at random.
The author is then used in combination with an author-topic distribution to choose a specific topic that this author writes about, and the word is then generated from this topic.
The purpose of using authorship information this way is to show patterns in which topics an author usually writes about, and be able to explore how related authors are to each other, based on what they write about.
\citeauthor{author_topic_2012} also show that the combination of authorship and \gls{lda} yield more coherent topics.
However, the Author-Topic model is applied to scientific article datasets, where the authors usually write about the same subject.
We apply this model to the Nordjyske news article dataset to see whether similar performance can be obtained.

\citet{MetaLDA2017} present a model, called MetaLDA, which can incorporate both metadata information and word embeddings within a topic model.
Since the field of incorporating word embeddings within generative topic models has gained popularity\cite{dieng2020topic}, \citet{MetaLDA2017} show how to use word embeddings for a variety of different datasets.
They also compare against a list of other models that take either metadata information or word embeddings into account when doing inference.
We take inspiration from \citet{MetaLDA2017}, but we do not employ the model they present. 
We adapt the Author-Topic model instead of MetaLDA because, in MetaLDA, each document has a specific Dirichlet prior for its topic distribution, which is computed from the metadata of the document, making it difficult to analyze the effect of a specific metadata type in a model that includes multiple metadata types.

\citet{tea_leaves} present different methods for evaluating probabilistic topic models. 
An important observation they made is that a good held-out likelihood, normally called perplexity, infers less semantically meaningful topics.
Due to this, we do not use perplexity as an evaluation metric.
\citet{topic_coherence_2015} introduce new measures for evaluating topic models, where some of them use the co-occurrence or conditional probability of words within topics to measure how coherent the topics are. 
In order to verify that these metrics work, they conduct a large user study in conjunction with these metric evaluations.
We use an evaluation metric called "Topic coherence" presented by \citet{topic_coherence_2015} to evaluate the topic quality of each of our models.

\citet{li2006pachinko} present a \gls{dag} structured topic model called the \acrfull{pam}, where topics are in a hierarchical structure, which allows it to find two types of topics, namely super-topics and sub-topics. 
\Gls{pam} is a generalization of the \gls{lda} model, where super and sub-topics are used to correlate topics within the model, e.g., a football topic being part of a sports topic.
We have a hierarchically structured taxonomy metadata within our dataset, which fits well with the hierarchical structure of this model.
We create a modified \gls{pam} to account for this metadata and investigate whether this type of information can improve the topic quality.

There also exist a variety of models that look at either document or word metadata.
Some examples of models that incorporate document-level metadata are: Supervised LDA (sLDA) by \citet{blei2010supervised}, Labelled LDA (LLDA) by \citet{llda2009}, and the Dirichlet Multinomial Regression (DMR) model by \citet{mimno2008topic}.
SLDA learns a model given the restriction of only having one label per document, while LLDA allows multiple labels per document, though it requires the number of topics to be the same as the number of unique metadata labels.
DMR handles metadata similarly to MetaLDA~\cite{MetaLDA2017} by incorporating labels on the prior of the documents' topic distributions.
Examples of models that incorporate word-level metadata are: WF-LDA by \citet{wf-lda2010} and LF-LDA by \citet{lf-lda2015}.
WF-LDA extends \gls{lda} by using word features to make a prior for the topics.
LF-LDA takes the approach of replacing \gls{lda}'s topic-word Dirichlet multinomial component with a two-component mixture of a topic-word Dirichlet multinomial component and a latent feature component.
We focus specifically on document-level metadata since this is easily available in our dataset.

Some of these works have shortcomings that we want to account for.
The model may not be built around incorporating metadata, such as the \gls{pam}~\cite{li2006pachinko}, which then has to be modified.
The metadata may be incorporated in the model in such a way that a deeper analysis of the becomes difficult, such as with the MetaLDA model~\cite{MetaLDA2017}.
It may also simply be that the work does not explore multiple types of metadata for their models, which is the case for the author-topic model~\cite{author_topic_2012}.

From these works, we adapt the concepts from \citet{author_topic_2012} for new models that can handle the unique characteristics of our dataset and support a deeper exploration of the models.
As mentioned earlier, one of the main reasons why we use the concepts from the Author-Topic model instead of the newer MetaLDA model~\cite{MetaLDA2017} is because each document in MetaLDA has a topic distribution that is based on the document's metadata.
Analyzing such a model that includes multiple metadata can be complicated, while in the author-topic model, other metadata can be included as their own meta-topic distributions and be analyzed further.
Also, since MetaLDA uses the document-topic distribution as its base, we would not be able to explore other interesting connections, such as the connection between learned category-topic distributions and the topics that are most probable for specific categories.
We also explore whether adapting the \gls{pam}~\cite{li2006pachinko} to work with a hierarchically structured taxonomy metadata, described in \autoref{sec:dataset_taxonomy}, gives the model more context and improves the topic quality or performance.
