\section{Introduction}\label{sec:introduction}
% Intro to recommendation and techniques
News is being broadcast every day around the world in the form of news articles, television, and newspapers, which supply people with the latest information.
Searching and categorizing the news is becoming a bigger problem since news is created at all times.
Topic modeling is an approach that takes a set of documents and generates topics that can be used for categorizing or annotating text documents, such as news articles~\cite{Probabilistic_Topic_Models}.

\Gls{lda} is a well-cited topic model which generates topics and topic distributions for documents based on the words in documents~\cite{blei2003latent}.
Extensions of \gls{lda} have also been proposed to model various other information sources to generate better topics and/or topics, however, with different focuses and potential uses.
In most models metadata is not used.\vejleder{er dette korrekt? + noget mere jeg ikke kan læse}
Author-Topic model by \citet{author_topic_2012} and the MetaLDA model by \citet{MetaLDA2017} being notable examples.

% Author-Topic
The Author-Topic model by \citet{author_topic_2012} combines the \gls{lda} model with author information to model the relationship between authors and the documents, which they have written.
This is based on the assumption that most authors usually write about only a few different topics.
By modeling this relationship, connections between authors and topics, and between different authors, can be inferred giving more underlying information to the topics.
They also show that the Author-Topic combination yields better and more coherent topics, which begs the question of whether any other document-related data can be applied similarly.
However, they only test their algorithm on scientific papers, where usually the authors write about the same subject (their research field), which might not be the case for other fields, like journalism. \vejleder{Ikke helt holdbart! På den anden side så ser man nok mere spredning i ?? inden du nyheder + news + forfattere}

% Intro to Nordjyske data and applications
We have a dataset from a danish media group, called Nordjyske, with three years of article data.
The dataset contains a variety of different metadata, which have the potential to improve topic models in the same way as \citet{author_topic_2012}. 
In this paper, the dataset will be used with a focus on topic modeling and incorporation of metadata.

% Intro to meta data
The dataset used with a topic model can have a large impact on the topics generated.
When referring to a dataset, we talk about a dataset including metadata information.
One example of this could be the publication date of a text document. 
In most contexts, it is not needed to use and understand the document; however, it provides more context to the main content of the document: the text.
However, a lot of metadata is not used, either because it is not useful or we do not know how to use it properly. \vejleder{lidt ude af kontekst den her paragraf}

% In this paper
We want to construct different topic models that incorporate various metadata, to see whether incorporating this information changes the topic quality. \vejleder{hvorfor ikke blot integrate and extract models to include meta-info. Som vi gør i problemformuerlingen}
We also investigate differences between the produced topics for various models, to evaluate their potential uses.

% Problem Statement
We define the following research questions to investigate in this paper:

\begin{itemize}
	\item \textit{How can we establish models that incorporate metadata from the Nordjyske dataset?}
	\item \textit{How does including metadata within such models impact the resulting topics?}
\end{itemize}

% Contributions
Our work is similar in goal to that of \citet{MetaLDA2017} since we work with meta information and are applying it to an \gls{lda} model.
However, \citet{MetaLDA2017} learn a specific Dirichlet prior based on the meta-information given in their dataset, which gives a specific topic distribution for each meta-information field and in turn affect the document-topic distribution used with the \gls{lda}.
Instead of using the document-topic distribution for drawing word topics, we want to create a new meta-topic distribution which influences the drawn topics.
An example is the author-topic model from \citet{author_topic_2012}, where they also create a distribution for each author.
We investigate the effect that creating a meta-topic distribution for any specific meta-information, such as the author information, has on the resulting topics.
The intuition behind this is to create new topic models, which describe the data in a different way using topics that are influenced by metadata.
For example, if the metadata describes something about geographic locations, location-specific topics will be generated, which could be useful in many cases.
The metadata, within the Nordjyske dataset, includes author information, as well as higher-level categorical information, which will be described in \autoref{sec:dataset}.
These categorical metadata are the basis for the novelties in this paper, which is our category-topic model that makes a topic distribution for each category in the dataset and using \gls{pam} on an existing metadata hierarchy (taxonomy) by applying a locking mechanism.\vejleder{denne paragraf er lidt vanskelig at følge}

% Paper Structure
The paper is organized as follows:
\autoref{sec:dataset} describes the dataset and the metadata used in the evaluation.
In \autoref{sec:related_work}, we explore related work within topic modeling using metadata.
\autoref{sec:preliminaries} gives preliminary knowledge about the topic models we adapt, and \autoref{sec:plate_notation} describes our metadata topic models and shows the plate notation.
In \autoref{sec:experiment}, we set up an evaluation to test the performance of the different metadata topic models and present the results.
In \autoref{sec:discussion}, we analyze and discuss the results of our topic models.
Finally, in \autoref{sec:conclusion}, conclusions and future work are given.
